# DevOps Moment / Oh. So. DevOps
分享遇到就很DevOps的時刻。

* 如果您是第一次聽到DevOps或第一次閱讀個系列，建議您可以到我的[第一篇分享文章](https://github.com/EricWang8230/Blog/blob/main/oh_so_devops_1.md)裡面有`什麼是DevOps?`和`我認為的DevOps`給您參考。
* 另外，全系列文章只代表我個人遇到的實際案例並不代表所有的開發、維運人員都會這樣。也期許自己未來有一天能力和緣分達到之後我也可以遇到都市傳說的團隊。
* 文章提到的URL、IP等接使用XX,YY等替代

<br>

# 分享一個很半島鐵盒的技術問題

某天一個訊息出現在螢幕右方(對，又是螢幕右方)寫著`使用著回報XX服務一下可以連過一下又不能連，檢查服務日誌並沒有發現任何錯誤方便跟我一起看看嗎？`看啦，哪次不看了？

不過這個服務的建置我根本同頭到尾都沒有參與過我完全不知道這個服務的架構也不知道這服務在幹嘛更不會知道這服務出問題對公司有什麼影響，進入線上會議後我先請開發團隊說明以下幾點:
* 這個服務提供了什麼？
* 這個服務出問題對部門有什麼影響？
* 這個服務的架構以及用了什麼工具、是地端自架還是雲端代管、跟公司內網的關係等

不過開發團隊對於最後的網路架構說得很模糊，最後也只能靠問更多問題才得知這個服務的網路架構。
* 一個網站服務紀錄X提供給Y存取使用
* 雖然是內部服務但重要性幾乎等於正式環境，因為這服務算是產線一部分如果壞了那就不用出貨了
* 使用AWS Elastic Beanstalk + vpn只能透過公司內網存取

對於這個服務有了初步的了解再來開始詢問遇到什麼問題:

開發團隊表示收到使用著回報使用瀏覽器瀏覽網頁一下200一下轉圈圈總之就是陷入無限迴圈但是什麼都沒做一下又好了，開發團隊已經檢查過服務日誌並沒有發現任何異常所以懷疑是網路問題，但是他們並沒有網路查修的相關知識及經驗所以又找上我。

聽完問題之後腦中出現一段旋律，沒錯正是[半島鐵盒](https://youtu.be/duZDsG3tvoA?t=90)
```
已經習慣不去阻止你 過好一陣子 你就會回來
```
聽起來就跟這服務的症狀87%相似。

<br>

# 查修半島鐵盒問題的過程
通常這總一下可以一下不行的問題(排除服務本身沒有問題)那87%都是網路問題，不管是使用者的網路問題或是服務端的網路問題。對於這類的異常我通常會以[DDF](https://pbs.twimg.com/media/E-qVpszVkAERyvb.jpg)的方向作查修也就是:
* DNS
* DHCP
* Firewall

![image](https://user-images.githubusercontent.com/20296999/133916278-6aa4c6b5-99e6-45b4-ad73-cf04080232ae.png)

當下的思路如下:
* 使用`mtr`確認經過的節點以及有無掉封包
* 從使用著環境到服務端中間沒有額外的實體防火牆節點所以轉向檢查服務的Security Group確認Source IP設定正確
* 使用`telnet`確認443端口可以正常訪問
* 使用`dig`解析服務URL確定返回`兩個A Reocrd 私有IP`
* 個別對兩個私有IP進行telnet確認443端口可以連線
* 確認使用者環境的dhcp正常，拿到的IP也正常。
* 確認服務端的ec2 IP是由aws控制，機器起落會自動加入Load balancer，而Load balancer IP則由AWS控制。

眼尖的朋友可能在使用dig做解析的時候就發現問題了，不過我比較遲鈍我是在確認完Load balancer設定之後才意識到問題。

我們來看看dig的資訊:

```
dig xxx.yyy.com     
...

;; ANSWER SECTION:
xxx.yyy.com. 86400	IN	A	192.168.54.78
xxx.yyy.com. 86400	IN	A	192.168.54.87

;; Query time: 87 msec
;; SERVER: 192.168.87.87#53(192.168.87.87)
```

`192.168.87.87`是公司內網的DNS(這點也算是我的疏忽，忘記確認服務的DNS是地端還是雲上)解析`xxx.yyy.com`居然回了兩個`A Record` XD 難怪會一下可以一下不行，還記得上面提到的
```
機器起落會自動加入Load balancer，而Load balancer IP則由AWS控制。
```

開發團隊缺少網路相關知識的維運人員直接把AWS Load balancer的私有IP交給了管理地端DNS的團隊並要求設定A Record而地端DNS團隊也沒有確認就照設定了，問題來了AWS Load balancer的私有IP是會動態調整的如果今天AWS服務有狀況是會自動換一組新的IP這時候地端的DNS沒有更新就會解析到舊的IP那就會遇到一下可以用重新整理後不行的窘境。

<br>

# 我給開發團隊的建議處理方式
已經知道原因是地端配置了錯誤的DNS Record那就只要修正DNS Record即可，把原本的A Record換成CNAME問題就解決了。

此時開發人員一臉黑人問號的問我CNAME是什麼？ Ok很合理，如果開發人員一開始就知道CNAME是什麼大概也不會遇到今天這個問題。解釋完CNAME是什麼之後開case給地端DNS團隊修正設定將xxx.yyy.com對應到Load balancer的URL就可以了。

更新後的dig的資訊:

```
dig xxx.yyy.com     
...

;; ANSWER SECTION:
xxx.yyy.com. 27375 IN CNAME zzz.elb.amazonaws.com.
zzz.elb.amazonaws.com. 29	IN	A	192.168.54.78
zzz.elb.amazonaws.com. 29	IN	A	192.168.54.87

;; Query time: 87 msec
;; SERVER: 192.168.87.87#53(192.168.87.87)
```

<br>

# 總結
這次的案例是開發團隊一手包辦Dev+Ops可以說是多數人熟悉的一條龍DevOps團隊，可惜的是團隊中並沒有真正的維運人員而團隊成員也沒有足夠的網路知識所以最後敗在DNS設定。

回到第一篇我所說的[我認為的DevOps](https://github.com/EricWang8230/Blog/blob/main/oh_so_devops_1.md#%E6%88%91%E8%AA%8D%E7%82%BA%E7%9A%84devops)

> 對我來說DevOps最重要的並不是採用了什麼工具或做了什麼CI/CD，更不是所謂的工程師必須身兼二職(開發+維運)就是DevOps。

> 但是如果今天開發人員與維運人員願意互相交流只有雙方才有的知識又或是維運人員在初期加入開發人員的架構設計討論讓雙方都更了解在意的點以及架構，我覺得這樣就很DevOps而不是單純的開發人員也負責維運的工作，維運人員也參與程式設計。

這次的經驗再次讓我體悟到DevOps真的不只是用了什麼工具或做了什麼就是DevOps，我還是崇尚開發人員+維運人互相學習、合作完成專案才是DevOps，也再次感謝有這個機會讓我再次見證Oh. So. DevOps的時刻！
